---
title: Restauration PITR â€“ Part 7
author: Adrien Nayrat
type: post
date: 2015-03-22T12:25:41+00:00
aliases: /2015/03/22/restauration-pitr-part-7/
categories:
  - Postgres
tags:
  - postgres

---
Je profite d'un week end de mauvais temps (mâ€™empÃªchant de retourner en falaise ğŸ™ ) pour poursuivre mes articles sur Postgres.

Dans le prÃ©cÃ©dent article : [Backup, restauration - Part 6][1] J'ai Ã©voquÃ© la restauration PITR pour Point In Time Recovery. Je vous encourage vivement Ã  mettre en place ce qui va suivre afin de rÃ©duire la perte de donnÃ©es en cas de modification accidentelle sur des enregistrements : Un drop table par exemple.

<!--more-->

Pour la mettre en place il vous faut :

  * Une instance Postgres maÃ®tre.
  * Archivage des WAL, externalisÃ© de prÃ©fÃ©rence.

Je ne vais pas revenir sur la mise en place de l'archivage, je l'ai dÃ©jÃ  dÃ©taillÃ© dans les prÃ©cÃ©dents articles. Pour vous expliquer cette restauration je vais utiliser un scÃ©nario Â«Â catastropheÂ Â».

Il est 12H30 et on vous informe qu'une table a Ã©tÃ© supprimÃ©e par erreur sur un serveur de production.

La rÃ©plication que vous avez mis en place ne vous est d'aucune aide car l'opÃ©ration a Ã©tÃ© reportÃ©e sur le rÃ©plicat.

_Remarque : Avec la version 9.4 il est possible d'avoir un rÃ©plicat avec du retard. Avec un peu de chance l'opÃ©ration de suppression de la table n'est peut Ãªtre pas encore rÃ©alisÃ©e sur le rÃ©plicat._

Par chance, vous effectuez un backup full toutes les nuits Ã  1H00 et vous avez mis en place l'archivage des journaux. Leur nettoyage se fait aprÃ¨s le backup full grÃ¢ce Ã  >pg_archivecleanup.

Pour Ãªtre tranquille vous effectuez un checkpoint afin que les derniers journaux soient archivÃ©s. Ensuite vous stoppez votre instance Postgres et dÃ©placez le rÃ©pertoire (au cas oÃ¹).

Vous restaurez les fichiers du backup full. Il ne vous reste plus qu'a configurer correctement la restauration via le fichier recovery.conf.

Celui-ci devra contenir le paramÃ¨tre restore_command afin que Postgres rÃ©cupÃ©re les journaux de transactions archivÃ©s.

Il devra Ã©galement contenir un paramÃ¨tre pour la cible de rÃ©cupÃ©ration, Si on ne le spÃ©cifie pas le moteur va rejouer les journaux de transaction dans leur totalitÃ©, jusqu'au Â«Â drop tableÂ Â» fatal. Il est possible de demander la restauration jusqu'Ã  un point de restauration, une date ou un identifiant de transaction.

Pour approfondir : <http://docs.postgresqlfr.org/current/recovery-target-settings.html>

Revenons Ã  notre scÃ©nario, imaginons que nous souhaitons revenir Ã  la derniÃ¨re transaction jouÃ©e avant le drop fatal. En grattant un peu, on peut utiliser l'outilÂ  [pg_xlogdump](http://www.postgresql.org/docs/current/static/pgxlogdump.html) pour lire les journaux de transaction.

```
/usr/lib/postgresql/9.3/bin/pg_xlogdump 000000010000000300000066
rmgr: HeapÂ Â Â Â Â Â Â  len (rec/tot):Â Â Â Â  21/Â Â  197, tx:Â Â Â  1213547, lsn: 3/66000028, prev 3/650000F0, bkp: 1000, desc: insert: rel 1663/16486/16519; tid 0/2
rmgr: Transaction len (rec/tot):Â Â Â Â  12/Â Â Â  44, tx:Â Â Â  1213547, lsn: 3/660000F0, prev 3/66000028, bkp: 0000, desc: commit: 2015-03-22 12:23:35.834785 CET
rmgr: StandbyÂ Â Â Â  len (rec/tot):Â Â Â Â  16/Â Â Â  48, tx:Â Â Â  1213548, lsn: 3/66000120, prev 3/660000F0, bkp: 0000, desc: AccessExclusive locks: xid 1213548 db 16486 rel 16519
rmgr: StandbyÂ Â Â Â  len (rec/tot):Â Â Â Â  16/Â Â Â  48, tx:Â Â Â  1213548, lsn: 3/66000150, prev 3/66000120, bkp: 0000, desc: AccessExclusive locks: xid 1213548 db 16486 rel 16522
rmgr: StandbyÂ Â Â Â  len (rec/tot):Â Â Â Â  16/Â Â Â  48, tx:Â Â Â  1213548, lsn: 3/66000180, prev 3/66000150, bkp: 0000, desc: AccessExclusive locks: xid 1213548 db 16486 rel 16524
rmgr: HeapÂ Â Â Â Â Â Â  len (rec/tot):Â Â Â Â  26/Â  6642, tx:Â Â Â  1213548, lsn: 3/660001B0, prev 3/66000180, bkp: 1000, desc: delete: rel 1663/16486/11774; tid 7/35 KEYS_UPDATED
rmgr: HeapÂ Â Â Â Â Â Â  len (rec/tot):Â Â Â Â  26/Â  3270, tx:Â Â Â  1213548, lsn: 3/66001BA8, prev 3/660001B0, bkp: 1000, desc: delete: rel 1663/16486/11903; tid 46/44 KEYS_UPDATED
rmgr: HeapÂ Â Â Â Â Â Â  len (rec/tot):Â Â Â Â  26/Â  4774, tx:Â Â Â  1213548, lsn: 3/66002888, prev 3/66001BA8, bkp: 1000, desc: delete: rel 1663/16486/11821; tid 2/26 KEYS_UPDATED
rmgr: HeapÂ Â Â Â Â Â Â  len (rec/tot):Â Â Â Â  26/Â  5730, tx:Â Â Â  1213548, lsn: 3/66003B30, prev 3/66002888, bkp: 1000, desc: delete: rel 1663/16486/11786; tid 42/37 KEYS_UPDATED
rmgr: HeapÂ Â Â Â Â Â Â  len (rec/tot):Â Â Â Â  26/Â Â Â  58, tx:Â Â Â  1213548, lsn: 3/660051B0, prev 3/66003B30, bkp: 0000, desc: delete: rel 1663/16486/11786; tid 42/38 KEYS_UPDATED
rmgr: HeapÂ Â Â Â Â Â Â  len (rec/tot):Â Â Â Â  26/Â  7902, tx:Â Â Â  1213548, lsn: 3/660051F0, prev 3/660051B0, bkp: 1000, desc: delete: rel 1663/16486/11797; tid 0/80 KEYS_UPDATED
```

C'est un extrait du rÃ©sultat de la commande, le premiÃ¨re ligne indique un insert avec la transaction NÂ° 1213547, la ligne ne dessous indique un commit. En revanche Ã  la troisiÃ¨me ligne on est passÃ© Ã  la transaction 1213548 avec un lock suivi de plusieurs lignes indiquant un delete. Il s'agit du drop fatal.

On va donc revenir Ã  la transaction NÂ°1213547. Voici le contenu de mon fichier recovery.conf :

```
restore_command = 'rsync "192.168.1.128:/var/lib/postgresql/9.3/wal_archive/%f" "%p"'

recovery_target_xid = '1213547'
recovery_target_inclusive = 'true'
```

La directive recovery\_target\_inclusive indique au moteur s'il inclue la transaction correspondant au NÂ°1213547 ou s'il s'arrÃªte juste avant. Ainsi jâ€™aurais pu spÃ©cifier un xid de 1213548Â  et un target_inclusive Ã  Â«Â falseÂ Â» pour obtenir le mÃªme rÃ©sultat.

Ensuite il suffit de redÃ©marrer postgres, voici ce qu'on peut observer dans les logs :

```
2015-03-22 12:41:17 CET LOG:Â  database system was interrupted; last known up at 2015-03-22 12:22:59 CET
2015-03-22 12:41:17 CET LOG:Â  creating missing WAL directory "pg_xlog/archive_status"
2015-03-22 12:41:17 CET LOG:Â  starting point-in-time recovery to XID 1213547
2015-03-22 12:41:17 CET LOG:Â  connection received: host=[local]
2015-03-22 12:41:17 CET LOG:Â  incomplete startup packet
2015-03-22 12:41:18 CET LOG:Â  connection received: host=[local]
2015-03-22 12:41:18 CET FATAL:Â  the database system is starting up
2015-03-22 12:41:18 CET LOG:Â  restored log file "000000010000000300000065" from archive
2015-03-22 12:41:18 CET LOG:Â  redo starts at 3/65000028
2015-03-22 12:41:18 CET LOG:Â  consistent recovery state reached at 3/650000F0
2015-03-22 12:41:18 CET LOG:Â  connection received: host=[local]
2015-03-22 12:41:18 CET FATAL:Â  the database system is starting up
2015-03-22 12:41:19 CET LOG:Â  connection received: host=[local]
2015-03-22 12:41:19 CET FATAL:Â  the database system is starting up
2015-03-22 12:41:19 CET LOG:Â  restored log file "000000010000000300000066" from archive
2015-03-22 12:41:19 CET LOG:Â  recovery stopping after commit of transaction 1213547, time 2015-03-22 12:23:35.834785+01
2015-03-22 12:41:19 CET LOG:Â  redo done at 3/660000F0
2015-03-22 12:41:19 CET LOG:Â  last completed transaction was at log time 2015-03-22 12:23:35.834785+01
rsync: link_stat "/var/lib/postgresql/9.3/wal_archive/00000002.history" failed: No such file or directory (2)
rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1536) [Receiver=3.0.9]
2015-03-22 12:41:19 CET LOG:Â  selected new timeline ID: 2
rsync: link_stat "/var/lib/postgresql/9.3/wal_archive/00000001.history" failed: No such file or directory (2)
2015-03-22 12:41:19 CET LOG:Â  connection received: host=[local]
2015-03-22 12:41:19 CET FATAL:Â  the database system is starting up
rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1536) [Receiver=3.0.9]
```

On remarque que le moteur crÃ©Ã©e le rÃ©pertoire des journaux de transaction, ensuite la ligne suivante est assez explicite : Â«Â starting point-in-time recovery to XID 1213547Â Â». Quelques lignes plus bas on remarque qu'il rejoue les journaux de transaction (Â«Â restored log file Â«Â 000000010000000300000065Â Â» from archiveÂ Â»).

Il arrÃªte la restauration jusquâ€™Ã  la transaction spÃ©cifiÃ©e :

```
recovery stopping after commit of transaction 1213547, time 2015-03-22 12:23:35.834785+01
```

On remarque quelques lignes d'erreur correspondant Ã  la sortie de rsync. Visiblement il cherche Ã  copier plusieurs fichiers en Â«Â x.historyÂ Â».Â  En regardant dans le rÃ©pertoire d'archivage on constate que le moteur a crÃ©Ã© un fichier 00000002.history contenant :

`1Â Â Â Â Â Â  3/66000120Â Â Â Â Â  after transaction 1213547`

Point important Ã©galement, on constate que la numÃ©rotation des journaux de transaction a changÃ©e :

```
-rw------- 1 postgres postgres 16777216 marsÂ  22 12:23 000000010000000300000065
-rw------- 1 postgres postgresÂ Â Â Â Â  305 marsÂ  22 12:23 000000010000000300000065.00000028.backup
-rw------- 1 postgres postgres 16777216 marsÂ  22 12:41 000000010000000300000066
-rw------- 1 postgres postgres 16777216 marsÂ  22 12:46 000000020000000300000066
-rw------- 1 postgres postgresÂ Â Â Â Â Â  39 marsÂ  22 12:41 00000002.history
```

Le fichier Â«Â 000000010000000300000065Â Â» correspond au wal lors du pg_basebackup, Â«Â 000000010000000300000066Â Â» correspond au checkpoint que j'ai lancÃ© aprÃ¨s l'incident. AprÃ¨s la restauration on peut voir le fichier Â«Â 000000020000000300000066Â Â». Le huitiÃ¨me caractÃ¨re est passÃ© de 1 Ã  2.

En retournant dans les logs du moteur on peut lire la ligne suivante un peu plus bas : "selected new timeline ID: 2" En fait, lors de la restauration, Postgres crÃ©Ã©e une nouvelle [timeline](http://docs.postgresqlfr.org/current/continuous-archiving.html#backup-timelines). C'est un concept que j'aborderai plus tard, en attendant je vous invite Ã  voir cette prÃ©sentation sur le fonctionnement des timeline aprÃ¨s une restauration PITR :
<https://wiki.postgresql.org/images/e/e5/FOSDEM2013-Timelines.pdf>

**Bien entendu comme tout systÃ¨me de sauvegarde vous devez jouer la procÃ©dure afin de valider qu'il y a pas eu d'erreur ou oubli.**



 [1]: http://blog.anayrat.info/2015/02/26/backup-restauration-pitr-part-6/ "Backup, restauration â€“ Part 6"
